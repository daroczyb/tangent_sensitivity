{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import gradnet as gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_cifar_loader_basic(bs=100):\n",
    "    transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                                 train=True, \n",
    "                                                 transform=transform_train,\n",
    "                                                 download=True)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                                train=False, \n",
    "                                                transform=transform_test,\n",
    "                                                download=True) \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=bs, \n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=16)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=bs, \n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=True,\n",
    "                                              num_workers=16)\n",
    "    \n",
    "    grad_test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=1, \n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=True,\n",
    "                                              num_workers=16)\n",
    "    \n",
    "    return train_loader,test_loader,grad_test_loader\n",
    "\n",
    "def torch_mnist_loader_basic(bs=100):\n",
    "    transform_train = transforms.Compose([\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Scale()\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(root='data/',\n",
    "                                                 train=True, \n",
    "                                                 transform=transform_train,\n",
    "                                                 download=True)\n",
    "\n",
    "    test_dataset = torchvision.datasets.MNIST(root='data/',\n",
    "                                                train=False, \n",
    "                                                transform=transform_test,\n",
    "                                                download=True) \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=bs, \n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=16)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=bs, \n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=True,\n",
    "                                              num_workers=16)\n",
    "    grad_test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=1, \n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=True,\n",
    "                                              num_workers=16)\n",
    "    \n",
    "    return train_loader,test_loader,grad_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_train_step(model,device,optimizer,criterion,train_loader):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)[0]\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return\n",
    "\n",
    "def base_model_eval(model,device,test_loader,dbg):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)[0]\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return correct,total\n",
    "\n",
    "def stat_activations(model,device,test_loader,dbg):\n",
    "    n = 0\n",
    "    for im,l in test_loader:\n",
    "        im = im.to(device)\n",
    "        out = model_base(im)\n",
    "        out[1].type=torch.BoolType\n",
    "        if n==0:\n",
    "            l1 = out[1] #.detach().cpu().numpy().astype(np.bool)\n",
    "            l2 = out[2] #.detach().cpu().numpy().astype(np.bool)\n",
    "            l3 = out[3] #.detach().cpu().numpy().astype(np.bool)\n",
    "            l4 = out[4] #.detach().cpu().numpy().astype(np.bool)\n",
    "            n=1\n",
    "        else:\n",
    "            l1 = torch.cat((l1,out[1]),dim=0)\n",
    "            l2 = torch.cat((l2,out[2]),dim=0) #.detach().cpu().numpy().astype(np.bool)\n",
    "            l3 = torch.cat((l3,out[3]),dim=0) #.detach().cpu().numpy().astype(np.bool)\n",
    "            l4 = torch.cat((l4,out[4]),dim=0) #.detach().cpu().numpy().astype(np.bool)\n",
    "            \n",
    "    return torch.cat((l1,l2,l3,l4),dim=1).detach().cpu().numpy().astype(np.bool)\n",
    "            \n",
    "    #return l1.detach().cpu().numpy().astype(np.bool),l2.detach().cpu().numpy().astype(np.bool),l3.detach().cpu().numpy().astype(np.bool),l4.detach().cpu().numpy().astype(np.bool)\n",
    "\n",
    "def tangent_sens(x,model):\n",
    "    x.requires_grad = True\n",
    "    out = torch.sum(model(x)[0][0])\n",
    "    t0=time.time()\n",
    "    #for i in [5]: #range(len(out)):\n",
    "    grads = torch.autograd.grad(out,x,retain_graph=True,create_graph=True)[0]\n",
    "    n=0\n",
    "    for t in grads:\n",
    "        for k in t.flatten():\n",
    "            act_grad = torch.autograd.grad(k,model.parameters(),retain_graph=True,create_graph=True,allow_unused=True) #,allow_unused=True)\n",
    "    #       print(\"act:\",act_grad)\n",
    "            for l in act_grad:\n",
    "    #            print(\"\\tl:\",l)\n",
    "                if l!=None:\n",
    "                    if n==0:\n",
    "                    #fn+= [g.norm()**2 for g in l.flatten()] \n",
    "                        hess = l.flatten()\n",
    "                    else:\n",
    "                        hess = torch.cat((hess,l.flatten()))\n",
    "                    n+=1\n",
    "    #if i==0: \n",
    "    ts = torch.norm(hess)\n",
    "    #else:\n",
    "    #    ts +=torch.norm(hess)\n",
    "    print(time.time()-t0,\"sec\")\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8005 11.1 True\n",
      "device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dbg = open(\"tansens.dbg\",\"a\")\n",
    "print(torch.backends.cudnn.version(),torch.version.cuda,torch.cuda.is_available())\n",
    "print(\"device:\",device)\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 100\n",
    "learning_rate = 0.1\n",
    "train_loader,test_loader,grad_test_loader = torch_cifar_loader_basic(64)\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(4*4*64, num_classes)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.max_pool(self.conv1(x)))\n",
    "        x2 = self.relu(self.max_pool(self.conv2_drop(self.conv2(x1))))\n",
    "        x3 = x2.view(x2.size(0), -1)   \n",
    "        x4 = self.fc1(x3)\n",
    "        return x4,torch.sign(x1.flatten()),torch.sign(x2.flatten())\n",
    "\n",
    "class CNNc3(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNc3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(5*5*64, num_classes)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.max_pool(self.conv1(x)))\n",
    "        x2 = self.relu(self.max_pool(self.conv2_drop(self.conv2(x1))))\n",
    "        x3 = x.view(x2.size(0), -1)   \n",
    "        x4 = self.fc1(x3)\n",
    "        return x4,x1,x2\n",
    "    \n",
    "class MLP1x(nn.Module):\n",
    "    def __init__(self, dim, hidd, num_classes=10):\n",
    "        super(MLP1x, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim, hidd)\n",
    "        self.fc2 = nn.Linear(hidd, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.fc2 = nn.Linear(hidd, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.fc1(x.view(x.size(0), -1))\n",
    "        out2 = self.relu(out1)\n",
    "        out3 = self.fc2(out2)\n",
    "        return out3,out2\n",
    "    \n",
    "class MLP2x(nn.Module):\n",
    "    def __init__(self, dim, hidd, num_classes=10):\n",
    "        super(MLP2x, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim, hidd)\n",
    "        self.fc2 = nn.Linear(hidd, hidd)\n",
    "        self.fc3 = nn.Linear(hidd, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.fc2 = nn.Linear(hidd, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.fc1(x.view(x.size(0), -1))\n",
    "        out2 = self.relu(out1)\n",
    "        out3 = self.fc2(out2)\n",
    "        out4 = self.relu(out3)\n",
    "        out5 = self.fc3(out4)\n",
    "        return out5,torch.sign(out2),torch.sign(out4)\n",
    "    \n",
    "class MLP4x(nn.Module):\n",
    "    def __init__(self, dim, hidd, num_classes=10):\n",
    "        super(MLP4x, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim, hidd)\n",
    "        self.fc2 = nn.Linear(hidd, hidd)\n",
    "        self.fc3 = nn.Linear(hidd, hidd)\n",
    "        self.fc4 = nn.Linear(hidd, hidd)\n",
    "        self.fc5 = nn.Linear(hidd, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.fc2 = nn.Linear(hidd, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.fc1(x.view(x.size(0), -1))\n",
    "        out2 = self.relu(out1)\n",
    "        out3 = self.fc2(out2)\n",
    "        out4 = self.relu(out3)\n",
    "        out5 = self.fc3(out4)\n",
    "        out6 = self.relu(out5)\n",
    "        out7 = self.fc4(out6)\n",
    "        out8 = self.relu(out7)\n",
    "        out9 = self.fc5(out8)\n",
    "        return out9,torch.sign(out2),torch.sign(out4),torch.sign(out6),torch.sign(out8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]         307,300\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "            Linear-3                  [-1, 100]          10,100\n",
      "              ReLU-4                  [-1, 100]               0\n",
      "            Linear-5                  [-1, 100]          10,100\n",
      "              ReLU-6                  [-1, 100]               0\n",
      "            Linear-7                  [-1, 100]          10,100\n",
      "              ReLU-8                  [-1, 100]               0\n",
      "            Linear-9                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 338,610\n",
      "Trainable params: 338,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.29\n",
      "Estimated Total Size (MB): 1.31\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'states/mlp4x100_cifar_sgd_no_wd_0.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8f84a7fb9708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcorrect_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcorrect_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"states/mlp4x100_cifar_sgd_no_wd_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn38/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn38/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn38/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'states/mlp4x100_cifar_sgd_no_wd_0.ckpt'"
     ]
    }
   ],
   "source": [
    "directory = \"states\"\n",
    "\n",
    "try:\n",
    "    os.stat(directory)\n",
    "except:\n",
    "    os.mkdir(directory)\n",
    "\n",
    "model_base = MLP4x(dim=3*32*32,hidd=100).to(device)\n",
    "criterion_base = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.05\n",
    "optimizer_base = torch.optim.SGD(model_base.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "#optimizer_base = torch.optim.SGD(model_base.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "#optimizer_base = torch.optim.Adam(model_base.parameters(), lr=learning_rate)\n",
    "def update_lr(optimizer_base, lr):    \n",
    "    for param_group in optimizer_base.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "summary(model_base,input_size=(1,3,32,32))\n",
    "\n",
    "epochs = 200\n",
    "learning_rate = 0.05\n",
    "curr_lr = learning_rate\n",
    "\n",
    "tansens = open(\"ts_cifar_no_wd.dbg\",\"w\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t0 = time.time()\n",
    "    base_train_step(model_base,device,optimizer_base,criterion_base,train_loader)\n",
    "    t1 = time.time()    \n",
    "    correct_te, total_te = base_model_eval(model_base,device,test_loader,dbg)\n",
    "    correct_tr, total_tr = base_model_eval(model_base,device,train_loader,dbg)\n",
    "    torch.save(model_base.state_dict(), str(\"states/mlp4x100_cifar_sgd_no_wd_\"+str(epoch)+\".ckpt\"))\n",
    "    n=0\n",
    "            \n",
    "    t2 = time.time()    \n",
    "    l_tr = stat_activations(model_base,device,train_loader,dbg)\n",
    "    l_te = stat_activations(model_base,device,test_loader,dbg)   \n",
    "    t3 = time.time()    \n",
    "    np.save(\"states/mlp4x100_cifar_sgd_no_wd_te_\"+str(epoch)+\".npy\",l_te)\n",
    "    np.save(\"states/mlp4x100_cifar_sgd_no_wd_tr_\"+str(epoch)+\".npy\",l_tr)\n",
    "    print(epoch,correct_tr/total_tr,correct_te/total_te,\"in\",t3-t0,\"sec\",t1-t0,t2-t1,t3-t2,file=tansens)\n",
    "    tansens.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
